{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"STAGE 1: Core Biological Foundations for Bioinformatics","text":"<p>Welcome to Stage 1! As a Computer Science student, you're great at thinking about systems, data structures, and algorithms. This stage reframes the essential biology you need into those terms.</p> <p>Biology, at its core, is an information processing system. You're perfectly equipped to understand it from this perspective.</p>"},{"location":"#whats-inside","title":"What's Inside:","text":"<ul> <li>Genomics Basics: Understand the fundamental \"data types\" of biology (DNA, RNA, Protein) and the core \"algorithm\" (Central Dogma) that governs them.</li> <li>Data Formats: Learn how biological data is stored in standard file formats. Think of these as the JSON or XML of bioinformatics.</li> <li>Microbiome Introduction: A primer on a specific, high-demand field (microbiome analysis) and the data it generates.</li> </ul> <p>Let's get started. Dive into the subdirectories to begin.</p>"},{"location":"0_linux_basics/","title":"Stage 0: Mastering the Command Line Interface (CLI)","text":"<p>For a biologist entering bioinformatics, the command line is your new digital laboratory. It's where you'll run analyses, manage massive datasets, and automate your work. This stage will give you the foundational skills to navigate this powerful environment.</p>"},{"location":"0_linux_basics/#why-the-terminal-is-your-best-friend","title":"Why the Terminal is Your Best Friend","text":"<ul> <li>Power &amp; Flexibility: GUIs (Graphical User Interfaces) are easy, but they are limiting. The CLI allows you to chain commands together to perform complex tasks that would be impossible with a mouse.</li> <li>Automation: You can write scripts to automate repetitive tasks, saving you countless hours.</li> <li>Server Access: Most high-performance computing (HPC) clusters and cloud servers, where you'll do heavy-duty bioinformatics work, do not have a graphical interface. You must know the command line to use them.</li> </ul>"},{"location":"0_linux_basics/#your-first-steps-in-the-ubuntulinux-terminal","title":"Your First Steps in the Ubuntu/Linux Terminal","text":""},{"location":"0_linux_basics/#core-commands-every-bioinformatician-must-know","title":"Core Commands Every Bioinformatician Must Know","text":"Command Description Example <code>ls</code> List files and directories. <code>ls -lh</code> (long, human-readable) <code>pwd</code> Print Working Directory (shows where you are). <code>pwd</code> <code>cd</code> Change Directory. <code>cd /home/user/data</code> <code>cp</code> Copy a file or directory. <code>cp file1.txt file2.txt</code> <code>mv</code> Move or rename a file. <code>mv old_name.txt new_name.txt</code> <code>rm</code> Remove a file. (Use with caution!) <code>rm sample.fasta</code> <code>mkdir</code> Make a new directory. <code>mkdir new_project</code> <code>cat</code> Concatenate and print file content. <code>cat file.txt</code> <code>head</code> Show the first 10 lines of a file. <code>head data.csv</code> <code>tail</code> Show the last 10 lines of a file. <code>tail data.csv</code> <code>grep</code> Search for a pattern in a file. <code>grep \"gene_name\" annotation.gff</code>"},{"location":"0_linux_basics/#navigating-the-filesystem","title":"Navigating the Filesystem","text":"<ul> <li><code>.</code> refers to your current directory.</li> <li><code>..</code> refers to the parent directory (one level up).</li> <li><code>~</code> refers to your home directory.</li> <li><code>/</code> is the root directory of the entire filesystem.</li> </ul> <p>Pro Tip: Use the <code>Tab</code> key for auto-completion. Start typing a command or filename and press <code>Tab</code>\u2014the shell will try to finish it for you. This reduces typos and saves time.</p>"},{"location":"0_linux_basics/#nano-your-first-command-line-text-editor","title":"<code>nano</code>: Your First Command-Line Text Editor","text":"<p><code>nano</code> is a simple, beginner-friendly text editor.</p> <ul> <li>Open or create a file: <code>nano my_script.py</code></li> <li>Save: <code>Ctrl + O</code> (Write Out)</li> <li>Exit: <code>Ctrl + X</code></li> <li>The commands are always visible at the bottom of the screen.</li> </ul>"},{"location":"0_linux_basics/#neofetch-show-off-your-system","title":"<code>neofetch</code>: Show Off Your System","text":"<p><code>neofetch</code> is a fun command that displays a logo of your Linux distribution along with system information. It's a great way to quickly check your OS version, kernel, and hardware.</p> <p>To install it: <code>sudo apt update &amp;&amp; sudo apt install neofetch</code> To run it: <code>neofetch</code></p>"},{"location":"0_linux_basics/#essential-tips-for-terminal-use","title":"Essential Tips for Terminal Use","text":"<ol> <li>Don't Fear the Manual: The <code>man</code> command gives you the manual for any other command. Example: <code>man ls</code> will teach you all about the <code>ls</code> command's options.</li> <li>Redirection is a Superpower:<ul> <li><code>&gt;</code>: Redirects output to a file (overwrites the file).<ul> <li><code>ls -l &gt; file_list.txt</code> (saves the file list to a text file)</li> </ul> </li> <li><code>&gt;&gt;</code>: Appends output to a file.<ul> <li><code>echo \"New sample\" &gt;&gt; samples.txt</code> (adds a new line to the file)</li> </ul> </li> </ul> </li> <li>Piping (<code>|</code>) Chains Commands: Use the output of one command as the input for another. This is the key to building powerful workflows.<ul> <li><code>cat data.fastq | grep \"@read_id\" | head -n 5</code><ul> <li>This pipeline reads a FASTQ file, finds all the read ID lines, and shows you just the first 5.</li> </ul> </li> </ul> </li> </ol>"},{"location":"0_linux_basics/#basic-file-and-format-operations","title":"Basic File and Format Operations","text":"<p>As a bioinformatician, you'll constantly be looking at text files.</p> <ul> <li>Check file type: <code>file my_data.bam</code></li> <li>Count lines/words/characters: <code>wc -l my_sequences.fasta</code> (counts lines)</li> <li>Compressing files (essential for large data):<ul> <li><code>gzip my_large_file.fastq</code> (compresses to <code>.gz</code>)</li> <li><code>gunzip my_large_file.fastq.gz</code> (decompresses)</li> </ul> </li> <li>Viewing compressed files without decompressing:<ul> <li><code>zcat file.fastq.gz | head</code> (view the top of a gzipped file)</li> </ul> </li> </ul>"},{"location":"1_genomics_basics/","title":"1. Genomics Basics: The Information System of Life","text":"<p>Think of molecular biology as a computer system with its own data, storage, and processing rules.</p>"},{"location":"1_genomics_basics/#dna-rna-and-protein-the-core-data-structures","title":"DNA, RNA, and Protein: The Core Data Structures","text":"<ul> <li> <p>DNA (Deoxyribonucleic Acid): This is the hard drive. It's a massive, double-stranded string of characters (<code>A</code>, <code>T</code>, <code>C</code>, <code>G</code>). It stores the permanent blueprint for everything in an organism.</p> <ul> <li>Data Structure: A very long character array/string.</li> </ul> </li> <li> <p>RNA (Ribonucleic Acid): This is like RAM or a message queue. It's a temporary, single-stranded copy of a small segment of DNA (a gene). Its main character set is (<code>A</code>, <code>U</code>, <code>C</code>, <code>G</code>).</p> <ul> <li>Data Structure: A shorter, temporary character array/string.</li> </ul> </li> <li> <p>Protein: This is the application or executable. It's a sequence of amino acids (20 different characters) that folds into a 3D shape to do something\u2014like catalyze a reaction or form a structural component.</p> <ul> <li>Data Structure: A character array that maps to a complex 3D object.</li> </ul> </li> </ul>"},{"location":"1_genomics_basics/#the-central-dogma-the-core-algorithm","title":"The Central Dogma: The Core Algorithm","text":"<p>This is the fundamental data flow in the cell:</p> <p>DNA \u2192 (Transcription) \u2192 RNA \u2192 (Translation) \u2192 Protein</p> <ol> <li>Transcription: A process \"reads\" a gene from the DNA hard drive and creates a temporary RNA copy. It's like loading a program into memory.</li> <li>Translation: A ribosome \"executes\" the RNA message, reading it in 3-character chunks (codons) and assembling the corresponding protein.</li> </ol>"},{"location":"1_genomics_basics/#mutations-bugs-in-the-code","title":"Mutations: \"Bugs\" in the Code","text":"<p>A mutation is a change in the DNA sequence. This can be: *   A single character change (SNP): <code>A</code> becomes <code>G</code>. *   A deletion: A character is removed. *   An insertion: A new character is added.</p> <p>These \"bugs\" can be harmless, or they can alter the final protein, causing disease. Variant calling is the process of finding these differences between a sample's DNA and a reference standard.</p>"},{"location":"1_genomics_basics/#ngs-high-throughput-data-generation","title":"NGS: High-Throughput Data Generation","text":"<ul> <li>Next-Generation Sequencing (NGS): This isn't one thing, but a collection of technologies that allow us to read DNA/RNA sequences at massive scale (gigabytes to terabytes of data per run).<ul> <li>Illumina: The most common. It produces billions of short, highly accurate string reads (e.g., 150 characters long).</li> <li>Nanopore: A newer technology. It produces much longer reads (thousands of characters) but with a higher error rate. This is a classic trade-off: data volume/length vs. data accuracy.</li> </ul> </li> </ul>"},{"location":"1_genomics_basics/#common-biological-data-formats","title":"Common Biological Data Formats","text":"<p>Bioinformatics uses standardized text-based formats to store sequence data. Here are the most important ones to recognize.</p>"},{"location":"1_genomics_basics/#fasta","title":"FASTA","text":"<p>A simple format for storing one or more sequences. *   <code>&gt;</code> followed by a description line. *   The raw sequence on the following lines.</p> <pre><code>&gt;sequence_1 description of my sequence\nAGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATC\nGATCGATCGATCGATCGATCGATC\n&gt;sequence_2 another sequence\nAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCT\n</code></pre>"},{"location":"1_genomics_basics/#fastq","title":"FASTQ","text":"<p>The standard format for raw NGS reads. It's a FASTA file with added quality scores. *   <code>@</code>: Sequence identifier. *   Line 2: The raw sequence read. *   <code>+</code>: A separator. *   Line 4: The quality score for each base in the sequence (ASCII encoded).</p> <pre><code>@SEQ_ID_1\nGATTTGGGGTTCAAAGCAGTATCGATCAAATAGTAAATCCATTTGTTCAACTCACAGTTT\n+\n!''*((((***+))%%%++)(%%%%).1***-+*''))**55CCF&gt;&gt;&gt;&gt;&gt;&gt;CCCCCCC65\n</code></pre>"},{"location":"1_genomics_basics/#sambam","title":"SAM/BAM","text":"<p>The format for storing alignment data after mapping NGS reads to a reference genome. *   SAM is human-readable text. *   BAM is the compressed, binary version. *   It's a complex, tab-delimited format with a header section (<code>@HD</code>, <code>@SQ</code>) and an alignment section.</p> <p>Example SAM line:</p> <pre><code>read_1  99  chr1  713939  60  100M  =  714222  383  AGCT...  *\n</code></pre>"},{"location":"1_genomics_basics/#vcf-variant-call-format","title":"VCF (Variant Call Format)","text":"<p>The format for storing genetic variations (SNPs, indels). *   It has a meta-information header (<code>##</code>). *   A header line (<code>#CHROM</code>). *   Tab-delimited rows for each variant.</p> <p>Example VCF line:</p> <pre><code>#CHROM  POS     ID      REF  ALT  QUAL  FILTER  INFO\nchr1    100341  .       T    C    50    PASS    .\n</code></pre>"},{"location":"1_genomics_basics/#microbiome-basics-for-qiime2","title":"Microbiome Basics for QIIME2","text":"<ul> <li>What is a microbiome? A community of microorganisms (bacteria, fungi, viruses) living in a particular environment (e.g., human gut, soil).</li> <li>How do we study it? We can't easily culture most microbes. Instead, we sequence a specific \"marker gene\" that acts as a barcode for different species.</li> <li>16S rRNA Gene: This is the most common marker gene for bacteria. It has regions that are the same for all bacteria, and variable regions that are different between species. By sequencing this gene, we can identify \"who is there\" in a sample. QIIME2 is a powerful pipeline for analyzing this type of data.</li> </ul>"},{"location":"1_genomics_basics/#recommended-learning-resources","title":"\ud83d\udccc Recommended Learning Resources","text":""},{"location":"1_genomics_basics/#for-core-biology-concepts","title":"For Core Biology Concepts:","text":"<ul> <li>Khan Academy Biology: Excellent for foundational concepts of DNA, genes, and the central dogma. Visit here</li> <li>NCBI Bookshelf: A free online collection of biomedical books. \"The Cell: A Molecular Approach\" is a great reference. Visit here</li> </ul>"},{"location":"1_genomics_basics/#for-bioinformatics-specific-theory","title":"For Bioinformatics-Specific Theory:","text":"<ul> <li>Coursera - Bioinformatics for Beginners: A good, structured overview. Visit here</li> <li>YouTube - Omics Explained: Short, clear videos on complex topics like NGS and different 'omics fields. Visit channel</li> <li>YouTube - The Bioinformatics Coach: Practical tutorials and career advice. Visit channel</li> </ul>"},{"location":"1_genomics_basics/#for-data-formats","title":"For Data Formats:","text":"<ul> <li>FASTQ/FASTA: A quick visual guide</li> <li>SAM/BAM: SAM format specification (technical but definitive)</li> <li>VCF: VCF format specification</li> </ul>"},{"location":"2_data_formats/","title":"2. Data Formats: The \"File Types\" of Bioinformatics","text":"<p>To work with biological data, you need to parse its standard file formats. Here are the most common ones you'll encounter.</p>"},{"location":"2_data_formats/#fasta-fa-fasta","title":"FASTA (<code>.fa</code>, <code>.fasta</code>)","text":"<p>The simplest format. It's used for storing one or more sequences (DNA, RNA, or protein). A file containing multiple FASTA sequences is often called a \"multi-FASTA\" file.</p> <ul> <li> <p>Structure:</p> <ol> <li>A header line that starts with <code>&gt;</code>. This line contains the sequence ID and optional metadata.</li> <li>The raw sequence data on one or more subsequent lines.</li> </ol> </li> <li> <p>Example: <code>&gt;sequence1_id description of sequence     AGTCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGA     TCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATC     &gt;sequence2_id another sequence, different length     AGCTAGCTAGCTAGCT</code></p> </li> </ul>"},{"location":"2_data_formats/#fastq-fq-fastq","title":"FASTQ (<code>.fq</code>, <code>.fastq</code>)","text":"<p>The standard format for raw NGS data from sequencers. It's an extension of FASTA that adds a quality score for each base.</p> <ul> <li> <p>Structure: Always 4 lines per sequence read.</p> <ol> <li>Line 1: Starts with <code>@</code>, containing the sequence ID.</li> <li>Line 2: The raw sequence data (the \"read\").</li> <li>Line 3: Starts with <code>+</code>, and is sometimes followed by the same sequence ID again.</li> <li>Line 4: A string of ASCII characters representing the quality score for each base.</li> </ol> </li> <li> <p>What is the Quality Score?     It's a measure of the probability that the base was called incorrectly. The score is <code>Q = -10 * log10(P)</code>, where <code>P</code> is the error probability. A higher score means a more reliable base call. The score is encoded as an ASCII character to save space. For example, <code>!</code> is a low score, while <code>J</code> is a high score.</p> </li> <li> <p>Example: <code>@read_id_from_sequencer     GATTACAAGATAGATAGATAGATAG     +     !''*((((***+))%%%++)(%%%%</code></p> </li> </ul>"},{"location":"2_data_formats/#sambam-sam-bam","title":"SAM/BAM (<code>.sam</code>, <code>.bam</code>)","text":"<p>Sequence Alignment Map format. It is the universal format for storing results from mapping reads to a reference genome.</p> <ul> <li>SAM: A human-readable, tab-delimited text file.</li> <li>BAM: The binary, compressed, and indexed version of SAM. It's not human-readable and is what you'll use for most computational analyses because it's much more efficient.</li> </ul> <p>A SAM file has a header section (lines start with <code>@</code>) and an alignment section where each row is a read.</p> <ul> <li> <p>Example SAM line: <code>read_76  99  chr1  10050  60  100M  =  10250  300  AGCT...  FFFF...</code></p> </li> <li> <p>Key columns:</p> <ul> <li><code>read_76</code>: ID of the read.</li> <li><code>99</code>: A bitwise FLAG indicating properties of the alignment (e.g., read is paired, mapped in proper pair).</li> <li><code>chr1</code>: Reference sequence name (chromosome).</li> <li><code>10050</code>: 1-based leftmost mapping POSition.</li> <li><code>60</code>: MAPping Quality (MAPQ).</li> <li><code>100M</code>: CIGAR string, indicating how the read aligns (100 matches/mismatches).</li> </ul> </li> </ul>"},{"location":"2_data_formats/#vcf-vcf","title":"VCF (<code>.vcf</code>)","text":"<p>Variant Call Format. This file stores information about genetic variations (where a sample's DNA differs from the reference genome).</p> <ul> <li>Structure: A tab-delimited file with a header section (lines start with <code>##</code>) and a content section.</li> <li>Example VCF line: <code>chr1  10591  rs12345  A  G  100  PASS  DP=40;AF=0.5</code></li> <li>Key columns:<ul> <li><code>chr1</code>: Chromosome.</li> <li><code>10591</code>: Position on the chromosome.</li> <li><code>rs12345</code>: ID of the variant (often from a database like dbSNP).</li> <li><code>A</code>: The REFerence base.</li> <li><code>G</code>: The ALTernate base found in the sample.</li> <li><code>100</code>: QUALity score for the assertion.</li> <li><code>PASS</code>: FILTER status.</li> <li><code>DP=40;AF=0.5</code>: INFO field with more details (e.g., read depth, allele frequency).</li> </ul> </li> </ul>"},{"location":"2_data_formats/#gffgtf-gff-gtf","title":"GFF/GTF (<code>.gff</code>, <code>.gtf</code>)","text":"<p>General Feature Format. Used to store genome annotations. It describes where genes, exons, introns, etc., are located on a genome. GTF is a stricter version of GFF.</p> <ul> <li>Structure: A 9-column, tab-delimited file.</li> <li>Example GTF line: <code>chr1  ENSEMBL  exon  11869  12227  .  +  .  gene_id \"ENSG00000223972\"; transcript_id \"ENST00000456328\"; ...</code></li> <li>Key columns:<ol> <li><code>seqname</code>: Chromosome or contig.</li> <li><code>source</code>: Program that generated the feature.</li> <li><code>feature</code>: The feature type (e.g., <code>gene</code>, <code>exon</code>, <code>CDS</code>).</li> <li><code>start</code>: Start position.</li> <li><code>end</code>: End position.</li> <li><code>score</code>: A score.</li> <li><code>strand</code>: <code>+</code> or <code>-</code>.</li> <li><code>frame</code>: For coding sequences (CDS).</li> <li><code>attribute</code>: A semicolon-separated list of tags and values with more information.</li> </ol> </li> </ul>"},{"location":"2_data_formats/#bed-bed","title":"BED (<code>.bed</code>)","text":"<p>Browser Extensible Data format. A simple and flexible format for defining genomic regions. It's often used to represent ChIP-seq peaks, regions of interest, or gene locations for visualization in a genome browser like IGV or UCSC Genome Browser.</p> <ul> <li>Structure: A tab-delimited file with at least 3 columns.</li> <li>Example BED line (3 columns): <code>chr1   10000   10500</code></li> <li>Core columns:<ol> <li><code>chrom</code>: Chromosome name.</li> <li><code>chromStart</code>: Start position (0-based).</li> <li><code>chromEnd</code>: End position (1-based).</li> <li>Optional columns can provide a <code>name</code>, <code>score</code>, <code>strand</code>, and more.</li> </ol> </li> </ul>"},{"location":"3_microbiome_introduction/","title":"3. Microbiome Introduction (for QIIME2)","text":"<p>The microbiome is the collection of all microbes\u2014bacteria, archaea, fungi, viruses\u2014living together in a particular environment. This could be the human gut, a soil sample, or an ocean thermal vent.</p>"},{"location":"3_microbiome_introduction/#why-is-it-important-a-systems-view","title":"Why is it important? A Systems View","text":"<p>Think of a microbiome as a complex, dynamic system that interacts with its host or environment. From a data perspective, analyzing this system helps us understand its impact on health, disease, and ecology.</p> <ul> <li>Human Health: The gut microbiome is a classic example. It's strongly linked to immunity, digestion, vitamin production, and even mental health (the \"gut-brain axis\"). Imbalances (dysbiosis) are associated with conditions like IBD, obesity, and autoimmune disorders.</li> <li>Environmental Science: Soil microbes determine nutrient cycling and plant health. Marine microbes form the base of the ocean's food web and influence global carbon and nitrogen cycles.</li> <li>Biotechnology: Microbes are engineered to produce biofuels, enzymes, and pharmaceuticals.</li> </ul>"},{"location":"3_microbiome_introduction/#how-do-we-measure-it-16s-rrna-barcode-sequencing","title":"How do we measure it? 16S rRNA \"Barcode\" Sequencing","text":"<p>It's too expensive and difficult to sequence every single piece of DNA in a microbial sample (an approach called \"shotgun metagenomics\"). Instead, we use a clever shortcut for taxonomic profiling: amplicon sequencing, most commonly of the 16S rRNA gene.</p> <ul> <li>The 16S rRNA gene is a specific gene that all bacteria and archaea have. It's part of the ribosome, the cell's protein-making machinery.</li> <li>Parts of this gene are highly conserved (the same across species), which is great for designing universal PCR primers to \"amplify\" or copy the gene.</li> <li>Other parts are hypervariable (different between species). These variable regions act as a \"barcode\" or \"fingerprint\".</li> <li>By sequencing just this one gene, we can identify which bacteria are present and get a relative idea of their abundance. This is a cost-effective snapshot of the community.</li> </ul>"},{"location":"3_microbiome_introduction/#what-is-qiime-2","title":"What is QIIME 2?","text":"<p>QIIME 2 (Quantitative Insights Into Microbial Ecology 2) is an open-source bioinformatics pipeline for analyzing microbiome data, primarily from amplicon sequencing.</p> <p>It's a powerful framework that takes you all the way from raw sequencing files to publication-quality graphics and statistics.</p>"},{"location":"3_microbiome_introduction/#the-qiime-2-artifact-qza-qzv","title":"The QIIME 2 \"Artifact\" (<code>.qza</code> / <code>.qzv</code>)","text":"<p>A core concept in QIIME 2 is the \"Artifact\". All data files generated by QIIME 2 are stored in this format. *   <code>.qza</code>: A QIIME 2 Artifact that contains data (e.g., your FASTQ files, a feature table). *   <code>.qzv</code>: A QIIME 2 Visualization. This is also an artifact, but it's a viewable output (e.g., a bar chart, a PCoA plot).</p> <p>An artifact is just a ZIP file containing the data itself, plus critical metadata about how it was generated (provenance). This is fantastic for reproducibility. You can inspect and extract data from them using <code>qiime tools export</code> or view them at view.qiime2.org.</p>"},{"location":"3_microbiome_introduction/#a-typical-qiime-2-workflow-conceptual","title":"A Typical QIIME 2 Workflow (Conceptual)","text":"<ol> <li>Import Data: Raw FASTQ files are imported into a QIIME 2 artifact (<code>.qza</code>).</li> <li>Denoise Reads: The raw reads are quality-filtered, and sequencing errors are corrected. This step clusters the reads into \"Amplicon Sequence Variants\" (ASVs), which represent unique microbial sequences. The main algorithm for this is DADA2.<ul> <li>Output: A Feature Table (which microbes are in which samples) and Representative Sequences (the actual DNA sequence of each ASV).</li> </ul> </li> <li>Assign Taxonomy: The representative sequences (ASVs) are matched against a reference database (e.g., Greengenes, SILVA) to assign taxonomic names (from Kingdom down to Species, if possible).</li> <li>Build a Phylogeny: A phylogenetic tree is built from the representative sequences to understand the evolutionary relationships between the microbes.</li> <li>Analyze Diversity: This is where you answer biological questions!<ul> <li>Alpha Diversity: Measures the diversity within a single sample. How many different species are there (richness)? How evenly are they distributed (evenness)?</li> <li>Beta Diversity: Measures the diversity between samples. How different is the microbial community of sample A from sample B? This is often visualized with Principal Coordinate Analysis (PCoA) plots.</li> </ul> </li> <li>Statistical Analysis: Identify microbes that are differentially abundant between different groups (e.g., healthy vs. disease) using statistical tests.</li> </ol>"},{"location":"3_microbiome_introduction/#next-steps","title":"Next Steps","text":"<p>The best way to learn QIIME 2 is to run it. Your next step should be to follow the official \"Moving Pictures\" tutorial, which walks you through a complete analysis.</p> <p>\u27a1\ufe0f QIIME 2 \"Moving Pictures\" Tutorial</p>"},{"location":"blog/2025-11-30-day-1/","title":"Day 1: My First Blog Post!","text":"<p>Date: 2025-11-30</p> <p>Today, I learned how to set up this blogging section on my bioinformatics journey website!</p> <p>Here are the key things I did:</p> <ul> <li>Created a new <code>blog</code> directory inside the <code>docs</code> folder.</li> <li>Added a new markdown file for my first post.</li> <li>Updated the <code>mkdocs.yml</code> file to include a \"Daily Blogging\" section in the navigation bar.</li> </ul> <p>This is a great way for me to keep track of my progress and document what I'm learning each day. I'm excited to continue this journey!</p>"},{"location":"stage2/","title":"STAGE 2: Master the 3 Fundamental Tools","text":"<p>These three tools are the bread and butter of bioinformatics. They are used everywhere, including in top research labs in India and globally. Mastering them will give you a solid practical foundation.</p> <ol> <li>BLAST: For finding similar sequences.</li> <li>Biopython: For automating biological data processing with Python.</li> <li>QIIME2: For analyzing microbial community data.</li> </ol>"},{"location":"stage2/1_BLAST/","title":"BLAST \u2014 Your First Tool","text":"<p>\ud83d\udca1 Purpose: Sequence similarity search. Given a sequence, BLAST finds regions of similarity against a massive database of known sequences.</p> <p>\ud83e\uddea Use Cases: *   Identifying unknown sequences: You have a piece of DNA, what is it? *   Checking for contamination: Are there non-target sequences in your sample? *   Finding homologous genes: Finding genes with shared ancestry in other species.</p>"},{"location":"stage2/1_BLAST/#getting-started","title":"Getting Started","text":"<p>The easiest way to start is with the web interface.</p> <p>\ud83d\udcda Web Resource: https://blast.ncbi.nlm.nih.gov</p>"},{"location":"stage2/1_BLAST/#core-concepts-to-learn","title":"Core Concepts to Learn","text":"<ul> <li>BLASTn: Nucleotide BLAST (DNA vs DNA database).</li> <li>BLASTp: Protein BLAST (Protein vs Protein database).</li> <li>E-value (Expect value): The number of hits you would expect to see by chance. Lower is better. An E-value of 0.001 is much more significant than an E-value of 10.</li> <li>Identity %: The percentage of characters that are identical between your query and the result.</li> <li>Query Coverage: The percentage of your query sequence that aligns with the result.</li> </ul>"},{"location":"stage2/2_Biopython/","title":"Biopython \u2014 Your First Bioinformatics Programming Skill","text":"<p>\ud83d\udca1 Purpose: Automate biological data tasks using Python. Instead of manually downloading files or converting formats, you can write scripts to do it for you. This is where your CS background gives you a huge advantage.</p>"},{"location":"stage2/2_Biopython/#core-tasks-you-will-learn","title":"Core Tasks You Will Learn","text":"<ul> <li>Parsing FASTA files: Read sequence data from a file into your Python program.</li> <li>Reading FASTQ files: Handle raw sequencing reads, including their quality scores.</li> <li>Running BLAST from Python: Automate sequence searches without using the web interface.</li> <li>Translating DNA to Protein: A classic bioinformatics exercise applying the central dogma.</li> <li>Fetching data from NCBI: Programmatically download data from the largest biological database.</li> </ul>"},{"location":"stage2/2_Biopython/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Install Biopython: <code>bash     pip install biopython</code> (Remember to use the pip from your virtual environment: <code>./venv/bin/pip install biopython</code>)</p> </li> <li> <p>Practice:     Work through 5-6 beginner scripts covering the tasks above. The official Biopython Tutorial and Cookbook is an excellent resource.</p> </li> </ol>"},{"location":"stage2/3_QIIME2/","title":"QIIME 2 \u2014 The Standard for Microbiome Analysis","text":"<p>\ud83d\udca1 Purpose: Analyze microbial community sequencing data (e.g., from 16S/18S/ITS rRNA gene sequencing). It takes you from raw sequence files to meaningful biological insights about what microbes are in your samples and how they differ.</p> <p>It is heavily used in premier research institutes like NICPR, ICMR-NIV, ICMR-IGIB, and most academic microbiome labs.</p>"},{"location":"stage2/3_QIIME2/#core-workflow-to-learn","title":"Core Workflow to Learn","text":"<ol> <li>Importing Data: Getting your raw FASTQ files into the QIIME 2 format.</li> <li>Denoising (with DADA2): A high-resolution method to filter out sequencing errors and identify unique sequences (called Amplicon Sequence Variants or ASVs).</li> <li>Taxonomic Assignment: Matching your ASVs against a reference database to give them names (e.g., Escherichia coli).</li> <li>Diversity Analysis:<ul> <li>Alpha Diversity: How diverse is a single sample?</li> <li>Beta Diversity: How different are microbial communities between samples?</li> </ul> </li> <li>Visualization: Creating plots like PCoA (Principal Coordinates Analysis) to visualize community differences and phylogenetic trees to see evolutionary relationships.</li> </ol>"},{"location":"stage2/3_QIIME2/#getting-started","title":"Getting Started","text":"<p>Your experience with Docker and Shell is a huge plus here, as QIIME2 can be tricky to install directly.</p> <p>\ud83d\udcda Official Tutorials: https://docs.qiime2.org</p> <p>The official tutorials are the best place to start. They provide sample data and walk you through the entire standard workflow.</p>"},{"location":"stage3/","title":"STAGE 3: LEfSe \u2014 Identify Biomarkers","text":"<p>LEfSe stands for Linear Discriminant Analysis Effect Size. It is a statistical method used to find features (in this case, microbes) that are consistently different between biological groups.</p> <p>\ud83d\udca1 Purpose: It is used heavily in ICMR labs and other research institutes for biomarker discovery. It helps answer the question: \"Which specific microbes are more abundant in the 'Case' group versus the 'Control' group?\"</p>"},{"location":"stage3/#workflow","title":"Workflow","text":"<p>The typical workflow connects directly from your QIIME2 analysis:</p> <ol> <li>QIIME2 Output: Start with the abundance table and metadata generated by QIIME2.</li> <li>Format Conversion: Convert the QIIME2 data into the specific format required by LEfSe.</li> <li>Run LEfSe: Execute the LEfSe algorithm to identify differentially abundant microbes.</li> <li>Visualize Results: Generate an LDA score plot, which shows the microbes that are most characteristic of each group.</li> </ol>"},{"location":"stage3/#getting-started","title":"Getting Started","text":"<p>Running LEfSe can be complex. The easiest way to start is by using a web-based implementation.</p> <p>\ud83d\udcda Galaxy Server: The Galaxy project hosts a web-based version of LEfSe that is easy to use for beginners. You can upload your formatted data and run the analysis through a graphical interface.</p>"},{"location":"stage4/","title":"STAGE 4: Learn Genomics &amp; Transcriptomics Tools","text":"<p>These tools are essential for any research involving DNA (genomics) or gene expression (transcriptomics), particularly in areas like cancer research at NICPR/ICMR.</p> <p>This stage is broken down into two key areas:</p> <ol> <li>Essential Genomics Tools: The standard pipeline for processing raw DNA sequencing data to find genetic variants.</li> <li>Transcriptomics (RNA-Seq) Tools: The standard pipeline for analyzing gene expression data to see which genes are more or less active.</li> </ol>"},{"location":"stage4/1_Genomics_Tools/","title":"Essential Genomics Tools (WGS/WES Pipeline)","text":"<p>This is the mandatory toolkit for any research role involving Whole Genome Sequencing (WGS) or Whole Exome Sequencing (WES). The workflow involves taking raw sequencing data and processing it to identify genetic variants like SNPs and indels.</p> Tool Used For Description FastQC Quality Control Inspects your raw FASTQ files to check for quality issues before you start analysis. Trimmomatic / Cutadapt Read Trimming Removes low-quality bases and adapter sequences from your reads. Garbage in, garbage out! BWA / Bowtie2 Read Alignment Aligns your cleaned reads to a reference genome, creating a SAM/BAM file. SAMtools BAM/SAM Handling A multi-tool for sorting, indexing, and viewing alignment files. Absolutely essential. GATK Variant Calling The industry standard for identifying differences (variants) between your sample and the reference genome. IGV Genome Visualization A desktop tool for visually inspecting your alignment (BAM) and variant (VCF) files. It lets you see the data."},{"location":"stage4/2_Transcriptomics_Tools/","title":"Transcriptomics (RNA-Seq) Tools","text":"<p>RNA-Seq measures the expression level of genes. The goal is often to find Differentially Expressed Genes (DEGs)\u2014genes that are significantly more or less active in one condition compared to another (e.g., tumor vs. normal tissue).</p> Tool Purpose Description HISAT2 / STAR Align RNA-Seq Reads Specialized aligners that are \"splice-aware,\" meaning they can handle the way RNA is processed in eukaryotes. StringTie / featureCounts Quantify Expression Counts how many reads map to each gene. This generates a table of raw counts. DESeq2 (in R) Differential Expression A very popular R package that takes raw counts and performs statistical analysis to find DEGs. EdgeR (in R) DEG Analysis An alternative, also very popular, R package for differential expression analysis. Enrichr / DAVID Pathway Analysis Once you have a list of DEGs, these tools help you figure out what biological pathways they are involved in (e.g., \"cell cycle\" or \"metabolism\")."},{"location":"stage5/","title":"STAGE 5: Explore Tools Used in ICMR/NICPR Labs","text":"<p>If you want to work in a top Indian research institute like ICMR or NICPR, it pays to know the specific tools they use. This list is based on their public workshops, research papers, and job requirements.</p> <p>Learning these shows that you are already aligned with their research priorities.</p>"},{"location":"stage5/#most-commonly-used-tools","title":"Most Commonly Used Tools:","text":"<ol> <li>QIIME 2: For microbiome analysis (as covered in Stage 2). A very in-demand skill.</li> <li>LEfSe: For biomarker discovery in microbiome data (as covered in Stage 3).</li> <li>R &amp; Bioconductor: The primary environment for statistical analysis, especially in cancer genomics. Packages like <code>DESeq2</code> and <code>edgeR</code> are run in R.</li> <li>GATK: The gold standard for variant calling in human genetics and cancer research (as covered in Stage 4).</li> <li>SPAdes / MEGAHIT: For de novo genome assembly (assembling a genome from scratch without a reference).</li> <li>MEGA / IQ-TREE / FastTree: For building phylogenetic trees (understanding evolutionary relationships).</li> <li>Docker / Singularity: For creating reproducible software environments. You already know Docker, which is a huge advantage. Singularity is a similar tool often used in High-Performance Computing (HPC) environments.</li> <li>HPC Clusters: Most serious NGS analysis is not run on a laptop. You'll need to be comfortable working on a command-line-only Linux server (HPC cluster) and using a job scheduler like Slurm or SGE.</li> </ol> <p>\ud83c\udfaf Focus Area: If you master QIIME2, LEfSe, GATK, and the basics of R, you can directly contribute to projects at NICPR, NIBMG, ICMR-IGIB, NCCS, NCBS, and top IITs.</p>"},{"location":"stage6/","title":"STAGE 6: Build 3 Strong Beginner Projects","text":"<p>A CV with practical, hands-on projects is far more impressive than a list of skills. These projects are designed to directly mirror the work done in labs at NICPR and ICMR, making you an incredibly attractive candidate for internships.</p> <ol> <li> <p>Project 1: Microbiome Analysis using QIIME2 + LEfSe</p> <ul> <li>Skill Shown: End-to-end microbiome data analysis. Highly relevant for NICPR.</li> </ul> </li> <li> <p>Project 2: BLAST + Biopython Automation</p> <ul> <li>Skill Shown: Core bioinformatics scripting and automation.</li> </ul> </li> <li> <p>Project 3: RNA-Seq Pipeline (FASTQ \u2192 DEG \u2192 Pathway Analysis)</p> <ul> <li>Skill Shown: Cancer genomics and transcriptomics analysis.</li> </ul> </li> </ol>"},{"location":"stage6/1_Project_Microbiome/","title":"Project 1: Microbiome Analysis using QIIME2 + LEfSe","text":"<p>\ud83c\udfaf Goal: Go from raw sequencing data to identifying key bacterial species that differ between two groups. This is a classic and highly valuable project.</p>"},{"location":"stage6/1_Project_Microbiome/#project-steps","title":"Project Steps:","text":"<ol> <li> <p>Find Data:</p> <ul> <li>Go to the NCBI Sequence Read Archive (SRA).</li> <li>Search for a 16S rRNA sequencing dataset that compares two simple groups (e.g., \"healthy\" vs. \"disease\" or two different environments).</li> <li>Download the raw FASTQ files for a small number of samples (e.g., 5 vs 5).</li> </ul> </li> <li> <p>Run the QIIME2 Pipeline:</p> <ul> <li>Follow the standard QIIME2 \"Moving Pictures\" tutorial workflow.</li> <li>Import your downloaded data.</li> <li>Run DADA2 for denoising and feature table creation.</li> <li>Assign taxonomy to your features.</li> <li>Generate alpha and beta diversity metrics and plots.</li> </ul> </li> <li> <p>Identify Biomarkers with LEfSe:</p> <ul> <li>Export your feature table and taxonomy from QIIME2.</li> <li>Format the data for LEfSe.</li> <li>Use a Galaxy server or a command-line installation of LEfSe to identify which microbes are significantly enriched in each of your groups.</li> </ul> </li> <li> <p>Report:</p> <ul> <li>Create a simple report (e.g., in a Jupyter Notebook or R Markdown file) that visualizes the diversity plots and the final LEfSe results.</li> <li>Explain your findings in simple terms.</li> </ul> </li> </ol>"},{"location":"stage6/2_Project_Automation/","title":"Project 2: BLAST + Biopython Automation","text":"<p>\ud83c\udfaf Goal: Showcase your scripting skills by creating a tool that automates a common bioinformatics task.</p>"},{"location":"stage6/2_Project_Automation/#project-steps","title":"Project Steps:","text":"<ol> <li> <p>Create an Input File:</p> <ul> <li>Create a multi-FASTA file containing several DNA or protein sequences. These can be sequences you get from NCBI or just example sequences.</li> </ul> </li> <li> <p>Write a Biopython Script (<code>blast_automation.py</code>):</p> <ul> <li>The script should take the multi-FASTA file as input.</li> <li>For each sequence in the file, it should:<ul> <li>Use Biopython's <code>Bio.Blast.NCBIWWW</code> module to run an online BLAST search (e.g., <code>blastn</code> for DNA, <code>blastp</code> for protein).</li> <li>Parse the XML output from the BLAST search.</li> <li>Extract the top hit (the one with the best E-value).</li> <li>From that top hit, extract key information: the organism name, the percent identity, the query coverage, and the E-value.</li> </ul> </li> </ul> </li> <li> <p>Generate an Output File:</p> <ul> <li>The script should write the extracted information into a clean, comma-separated values (<code>.csv</code>) file.</li> <li>The CSV should have clear headers like <code>Query_ID</code>, <code>Top_Hit_Organism</code>, <code>Percent_Identity</code>, <code>Query_Coverage</code>, <code>E-Value</code>.</li> </ul> </li> <li> <p>Put it on GitHub:</p> <ul> <li>Create a new repository on GitHub.</li> <li>Add your Python script and an example input file.</li> <li>Write a <code>README.md</code> explaining what the script does and how to run it. This demonstrates good documentation practice.</li> </ul> </li> </ol>"},{"location":"stage6/3_Project_RNASeq/","title":"Project 3: RNA-Seq Pipeline (FASTQ \u2192 DEG \u2192 Pathway Analysis)","text":"<p>\ud83c\udfaf Goal: Perform a complete differential gene expression analysis, a cornerstone of modern cancer research.</p>"},{"location":"stage6/3_Project_RNASeq/#project-steps","title":"Project Steps:","text":"<ol> <li> <p>Find Data:</p> <ul> <li>Go to the Gene Expression Omnibus (GEO) database.</li> <li>Find an RNA-Seq dataset that compares two conditions (e.g., a tumor type vs. adjacent normal tissue). Look for a study with a small number of samples to start (e.g., 3 vs 3).</li> <li>Use the SRA toolkit (<code>fastq-dump</code>) to download the raw FASTQ files.</li> </ul> </li> <li> <p>Run the Alignment and Counting Pipeline:</p> <ul> <li>Perform quality control with FastQC.</li> <li>Use HISAT2 or STAR to align the reads to the appropriate reference genome (human, mouse, etc.).</li> <li>Use featureCounts or StringTie to count how many reads map to each gene, creating a count matrix.</li> </ul> </li> <li> <p>Perform Differential Expression Analysis in R:</p> <ul> <li>Load the count matrix into R.</li> <li>Use the DESeq2 package to perform the statistical analysis.</li> <li>Generate a list of differentially expressed genes (DEGs) based on a significance threshold (e.g., p-adjusted value &lt; 0.05).</li> <li>Create a Volcano Plot to visualize the results, highlighting the most significant up-regulated and down-regulated genes.</li> </ul> </li> <li> <p>Perform Pathway Analysis:</p> <ul> <li>Take your list of significant DEGs.</li> <li>Use an online tool like Enrichr or DAVID to see which biological pathways are over-represented in your gene list.</li> </ul> </li> <li> <p>Report:</p> <ul> <li>Document your entire workflow, including the commands used and the R code.</li> <li>Display your volcano plot and the results from the pathway analysis.</li> <li>This is an advanced project that is highly relevant to cancer research at NICPR.</li> </ul> </li> </ol>"},{"location":"stage7/","title":"STAGE 7: Learn Cloud + Containers (The DevOps of Biology)","text":"<p>Your existing knowledge of Docker is a massive head start. In modern bioinformatics, being able to package your tools and run them anywhere is a critical skill. Labs and companies love this because it solves the \"it worked on my machine\" problem.</p> <p>Here's how to build on what you already know:</p>"},{"location":"stage7/#1-snakemake-nextflow-pipeline-automation","title":"1. Snakemake / Nextflow (Pipeline Automation)","text":"<ul> <li>What they are: Workflow management systems. They allow you to write scalable, reproducible pipelines that can run on anything from a laptop to an HPC cluster to the cloud.</li> <li>Why learn them: A single analysis can involve dozens of steps with different tools. A workflow manager automates this entire process, handles dependencies, and makes your work portable.</li> <li>Which one to choose:<ul> <li>Snakemake: Uses Python-like syntax, which might be more intuitive for you. It's very popular in academia.</li> <li>Nextflow: Has excellent support for cloud and HPC environments. It's heavily used in both industry and academia.</li> </ul> </li> <li>Recommendation: Start with the basic Snakemake tutorial. It will click very quickly with your programming background.</li> </ul>"},{"location":"stage7/#2-conda-mamba-environment-management","title":"2. Conda / Mamba (Environment Management)","text":"<ul> <li>What they are: Package and environment managers. <code>conda</code> is the original, <code>mamba</code> is a much faster, re-implementation of <code>conda</code>.</li> <li>Why learn them: Many bioinformatics tools have complex and conflicting dependencies. <code>conda</code> allows you to create isolated environments for each project, ensuring that Tool A doesn't break Tool B. It's an alternative to using Docker for everything.</li> </ul>"},{"location":"stage7/#3-git-github-version-control","title":"3. Git + GitHub (Version Control)","text":"<ul> <li>What it is: The standard for tracking changes in code and collaborating.</li> <li>Why it's critical: You need it to manage your own scripts, contribute to open-source bioinformatics projects, and share your work with colleagues. For a CS student, this is likely already a familiar skill, but if not, it is non-negotiable. You must learn it.</li> </ul>"}]}